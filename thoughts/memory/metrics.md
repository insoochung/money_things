---
updated: 2026-02-01
tracking_since: 2026-02-01
total_ideas: 0
---

# Decision Metrics

All metrics computed from `history/ideas/` files via `utils/metrics.py`. Never LLM-generated.

## Overall Performance

| Metric | Value |
|--------|-------|
| Total ideas | 0 |
| Acted | 0 |
| Passed | 0 |
| Win rate (acted) | - |
| Pass accuracy | - |

## By Conviction Level

| Conviction | Acted | Wins | Win Rate |
|------------|-------|------|----------|
| High | 0 | 0 | - |
| Medium | 0 | 0 | - |
| Low | 0 | 0 | - |

## By Theme

[Theme-specific win rates will appear here as ideas are tracked]

## Calibration Analysis

Compares stated conviction vs actual outcomes.

| Conviction | Expected Win Rate | Actual Win Rate | Calibration |
|------------|-------------------|-----------------|-------------|
| High | 70%+ | - | - |
| Medium | 50-70% | - | - |
| Low | 30-50% | - | - |

## Timeframe Accuracy

Compares stated timeframe vs actual holding period.

| Timeframe | Count | Avg Actual | Accuracy |
|-----------|-------|------------|----------|
| < 1 month | 0 | - | - |
| 1-3 months | 0 | - | - |
| 3-6 months | 0 | - | - |
| 6-12 months | 0 | - | - |
| > 12 months | 0 | - | - |
